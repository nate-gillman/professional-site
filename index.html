<Service!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <!-- Fonts and stuff -->
<!--    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,800italic,400,700,800' rel='stylesheet' type='text/css' />-->
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400italic,700italic,800italic,400,700,800' rel='stylesheet' type='text/css'/>
    <link rel="stylesheet" type="text/css" href="css/homepage.css" media="screen"/>
    <link rel="stylesheet" type="text/css" media="screen" href="css/iconize.css"/>
    <link rel="icon" href="images/favicon.ico" type="image/x-icon"/>
    <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon"/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script>
          $(function()
          {
                $('#header').load('header.html');
                $('#footer').load('footer.html');
                $('#title').load('title.html');
          });

    </script>
    <div id="header"></div>

    <script async src="https://platform.twitter.com/widgets.js"></script>
    <script>
        // Wait for Twitter widgets to load
        window.twttr = (function(d, s, id) {
            var js, fjs = d.getElementsByTagName(s)[0],
                t = window.twttr || {};
            if (d.getElementById(id)) return t;
            js = d.createElement(s);
            js.id = id;
            js.src = "https://platform.twitter.com/widgets.js";
            fjs.parentNode.insertBefore(js, fjs);
            t._e = [];
            t.ready = function(f) {
                t._e.push(f);
            };
            return t;
        }(document, "script", "twitter-wjs"));
    
        function embedTweet(tweetUrl, containerId) {
            // Clear any existing tweets
            document.getElementById(containerId).innerHTML = '';
            
            // Create tweet embed
            twttr.widgets.createTweetEmbed(
                tweetUrl.split('/').pop(), // Get tweet ID from URL
                document.getElementById(containerId),
                {
                    conversation: 'none',    // Hide replies
                    cards: 'visible',        // Show cards
                    width: 550,              // Set width
                    align: 'center',         // Center alignment
                    theme: 'light',          // Use light theme
                    hideCard: false,         // Show the card
                    hideThread: false,       // Show the thread
                    dnt: false              // Show all engagement metrics
                }
            );
        }
    
        // Initialize tweet embeds when the page loads
        window.onload = function() {
            embedTweet('https://x.com/GillmanLab/status/1852015295470166477', 'tweet-container-fourier-head');
            embedTweet('https://x.com/GillmanLab/status/1760342830013206760', 'tweet-container-scsc');
            // You can add more tweet embeds here by calling embedTweet with different URLs and container IDs
        };
    </script>

</head>

<body>
<div id="content">
    <div id="content-inner">

        <div id="title"></div>

        <ul id="tabs">
            <li><a href="index.html" class="selected">About</a></li>
            <li><a href="teaching.html">Teaching</a></li>
        </ul>

        

        <div class="tabContent" id="index.html">
            <div class="section">

                

                <img src="images/nate_headshot.png" width="300" align="left" alt="Nate Gillman"
                     style="margin-left:0px;margin-right:20px; border:1px solid #8a887d"/>
                Howdy!! I'm a PhD student at <a href="https://brown.edu/" target="_blank">Brown University</a>, 
                where I'm fortunate to be advised by
                <a href="https://chensun.me/" target="_blank">Chen Sun</a>.
                I'm supported by Brown's 
                <a href="https://www.brown.edu/academics/math/" target="_blank">Department of Mathematics</a> and 
                <a href="https://cs.brown.edu/" target="_blank">Department of Computer Science</a>.
                I study <b>machine learning</b>, <b>computer vision</b>, and <b>artifical intelligence</b>.
                My current projects focus on <b>generative modeling</b>, 
                applied to various domains.
                In particular, I like building generative models with 
                <a href="https://nategillman.com/fourier-head" target="_blank">mathematical</a> or 
                <a href="https://nategillman.com/sc-sc" target="_blank">physical</a>
                inductive biases that make their outputs more realistic. 
                If you're at Brown and you're interested in working on a research project with me, that's awesome!!
                Please email me directly, and attach your CV and transcripts.

                <br/><br/>
                In the past I also did work in cryptography and pure mathematics, including number theory, 
                algebraic geometry, and geometric measure theory.
                <i>Fun fact:</i> I actually started grad school as a PhD student in Brown's 
                math department, conducting research in analytic number theory and cryptography with 
                <a href="https://www.brown.edu/academics/math/people/jeffrey-hoffstein" target-"_blank">Jeff Hoffstein</a>.
                I've since switched to AI, but I still like to make my background in pure math 
                <a href="http://bit.ly/3NxHH4p" target="_blank">useful</a>
                in
                <a href="https://nategillman.com/sc-sc.html" target="_blank">my</a> 
                AI
                <a href="https://nategillman.com/fourier-head" target="_blank">research</a>.
                After getting my masters degree in mathematics in spring 2022, I took a professional leave of absence 
                for a year to gain exposure to ML in industry. I did three internships: at 
                <a href="https://www.americanexpress.com/en-us/careers/" target="_blank">American Express AI Labs</a>
                , 
                <a href="https://www.akkio.com/" target="_blank">Akkio</a>
                (a no-code AI startup), and 
                <a href="https://www.captions.ai/" target="_blank">Captions</a>
                 (an AI video editing startup).
                <br/><br/>



<!--                <div class="highlight">
                    <b>Prospective Students</b>: DELETE THIS
                </div><br/><br/><br/><br/><br/>
-->

		I completed my undergraduate degree at 
        <a href="https://www.wesleyan.edu/" target="_blank">Wesleyan University</a>. During my time in college I spent one semester at the 
        <a href="https://mathinmoscow.org/" target="_blank">Math in Moscow</a> program and another at the
        <a href="https://www.bsmath.hu/CURRENT/index.html" target="_blank">Budapest Semesters in Mathematics</a> program.
        My undergraduate math research advisor was 
        <a href="https://uva.theopenscholar.com/ken-ono" target="_blank">Ken Ono</a>,
        I spent two summers doing research with him at Emory University's
        <a href="https://uva.theopenscholar.com/ken-ono/reus-archive-2019" target="_blank">Research Experience for Undergraduates</a>.
        <br/><br/>

        I'm particularly inspired by the life of 
        <a href="https://en.wikipedia.org/wiki/Walter_Pitts" target="_blank">Walter Pitts</a>,
        who proposed the first mathematical model of the neural network.        

        <br/><br/>

                <center>
                    <a href="misc/Gillman_resume.pdf" target="_blank">Resume</a>
                    &nbsp;/&nbsp; 
                    <a href="https://scholar.google.com/citations?user=twg9zD0AAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a>
                    &nbsp;/&nbsp; <a href="https://www.semanticscholar.org/author/Nate-Gillman/66688357" target="_blank">Semantic Scholar</a>
                    &nbsp;/&nbsp; 
                    <a href="https://github.com/nate-gillman" target="_blank">Github</a>
                    <!-- &nbsp;/&nbsp; <a href="https://mathscinet.ams.org/mathscinet/MRAuthorID/1289272" target="_blank">MathReviews</a> -->
                    &nbsp;/&nbsp; 
                    <a href="https://arxiv.org/a/gillman_n_1.html" target="_blank">arXiv</a>
                    &nbsp;/&nbsp; 
                    <a href="https://www.linkedin.com/in/ngillman/" target="_blank">LinkedIn</a>
                    &nbsp;/&nbsp; 
                    <a href="https://twitter.com/GillmanLab" target="_blank">Twitter</a>
                    <br/>
                     <h3>nate_gillman [at] brown.edu</a></h3>
                </center>
            </div>

            

            <div class="section">
                <hr class="smooth">
                <h3><u>Publications (AI/ML)</u></h3>

				<b>2024</b>

                <div class="publist">
                    <a>
                        <img src="pubs/thumbs/fourier-head.gif" width="140" align="left"
                             style="margin-left:0px;margin-right:20px; border:1px solid #ddd"/>
                    </a>
                    <a href="pubs/fourier-head.pdf" target="_blank">
                        <b><i><img src="fourier-head-static/images/favicon.ico" alt="image" style="width: 24px; height: 24px; vertical-align: text-top;">Fourier Head: Helping Large Language Models Learn Complex Probability Distributions</i></b><br/>
                    </a>
                    <u>Nate Gillman</u><sup>*</sup>, Daksh Aggarwal<sup>*</sup>, Michael Freeman, Saurabh Singh, and Chen Sun. <i>ICLR 2025.</i>
                    <br/><br/><br/>
					<a href="https://arxiv.org/abs/2410.22269" target="_blank">arXiv</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://github.com/nate-gillman/fourier-head" target="_blank">Code</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://nategillman.com/fourier-head" target="_blank">Project Page</a>
                        
                </div>


                <div class="publist">
                    <a>
                        <img src="pubs/thumbs/sc-sc.gif" width="140" align="left"
                             style="margin-left:0px;margin-right:20px; border:1px solid #ddd"/>
                    </a>
                    <a href="pubs/sc-sc.pdf" target="_blank">
                        <b><i>Self-Correcting Self-Consuming Loops for Generative Model Training</i></b><br/>
                    </a>
                    <u>Nate Gillman</u>, Michael Freeman, Daksh Aggarwal, Chia-Hong Hsu, Calvin Luo, Yonglong Tian, and Chen Sun. <i>ICML 2024.</i>
                    <br/><br/>
					<a href="https://arxiv.org/abs/2402.07087" target="_blank">arXiv</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://github.com/nate-gillman/self-correcting-self-consuming" target="_blank">Code</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://nategillman.com/sc-sc.html" target="_blank">Project Page</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://icml.cc/virtual/2024/poster/33370" target="_blank">Conference</a>
                        
                </div>

				<b>2022</b>

                <div class="publist">
                    <a>
                        <img src="pubs/thumbs/skewered_meatball.png" width="140" align="left"
                             style="margin-left:0px;margin-right:20px; border:1px solid #ddd"/>
                    </a>
                    <a href="pubs/isoscore.pdf" target="_blank">
                        <b><i>IsoScore: Measuring the Uniformity of Embedding Space Utilization</i></b><br/>
                    </a>
                    William Rudman, <u>Nate Gillman</u>, Taylor Rayne, and Carsten Eickhoff. <i>ACL 2022.</i>
                    <br/><br/><br/>
					<a href="https://arxiv.org/abs/2108.07344" target="_blank">arXiv</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a
                        href="https://github.com/bcbi-edu/p_eickhoff_isoscore" target="_blank">Code</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://aclanthology.org/2022.findings-acl.262/" target="_blank">Conference</a>
                        
                </div>

                <h3><u>Patents (AI/ML)</u></h3>
				<b>2022</b>

                <div class="publist">
                    <!-- <a>
                        <img src="pubs/thumbs/skewered_meatball.png" width="115" align="left"
                             style="margin-left:0px;margin-right:20px; border:1px solid #ddd"/>
                    </a> -->
                    <a href="https://patents.google.com/patent/WO2024073098A1/" target="_blank">
                        <b><i>
                            Methods and systems for automatically generating and executing computer code using a natural language description of a data manipulation to be performed on a data set</i></b><br/>
                    </a>
                    <u>Nate Gillman</u>, Nadia Laflaf, Abraham Parangi, Jonathon Reilly, and Nathan Wies.
                    <i>U.S. Patent Application No. WO 2024/073098 A1.</i> Filed Sep 29, 2023.
                    <!-- <br/><br/>
					<a href="https://arxiv.org/abs/2108.07344" target="_blank">arXiv</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a
                        href="https://github.com/bcbi-edu/p_eickhoff_isoscore" target="_blank">Project Page</a> -->
                        
                </div>
		    
                <h3><u>Publications (Mathematics)</u></h3>
				<b>2021</b>

				<div class="publist">
                    <a>
                        <img src="pubs/thumbs/injective_projections_v3.png" width="140" align="left"
                             style="margin-left:0px;margin-right:20px; border:1px solid #ddd"/>
                    </a>
                    <a href="pubs/injective_projections.pdf" target="_blank">
                        <b><i>Large sets with small injective projections</i></b><br/>
                    </a>
                    Frank Coen, <u>Nate Gillman</u>, Tamás Keleti, Dylan King, and Jennifer Zhu (2021).
                    <i>Annales Fennici Mathematici</i>, <b>46</b>(2), 683-702.
                    <br/><br/>
					<a href="https://arxiv.org/abs/1906.06288" target="_blank">arXiv</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://afm.journal.fi/article/view/110570" target="_blank">Journal</a>
                </div>
				<b>2020</b>


				<div class="publist">
                    <a href="https://wstein.org/talks/2013-madison/" target="_blank">
                        <img src="pubs/thumbs/sato_tate_animation_v3.gif" width="140" align="left"
                             style="margin-left:0px;margin-right:20px; border:1px solid #ddd"/>
                    </a>
                    <a href="pubs/sato_tate.pdf" target="_blank">
                        <b><i>Patterns of primes in the Sato-Tate conjecture</i></b><br/>
                    </a>
                   <u>Nate Gillman</u>, Michael Kural, Alexandru Pascadi, Junyao Peng, and Ashwin Sah (2020).
                    <i>Research in Number Theory</i>, <b>6</b>(9).

                   <br/><br/>
					<a href="https://arxiv.org/abs/1907.08285" target="_blank">arXiv</a>
					&nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://doi.org/10.1007/s40993-019-0184-8" target="_blank">Journal</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=MR4048052" target="_blank">MathSciNet </a>
                </div>

				<div class="publist">
                    <a href="https://math.stackexchange.com/questions/584283/what-does-cusp-form-mean" target="_blank">
                        <img src="pubs/thumbs/cusp_form.jpeg" width="140" align="left"
                             style="margin-left:0px;margin-right:20px; border:1px solid #ddd"/>
                    </a>
                    <a href="pubs/subconvexity.pdf" target="_blank">
                        <b><i>Explicit subconvexity savings for sup-norms of cusp forms on PGL(n,R)</i></b><br/>
                    </a>
                    <u>Nate Gillman</u> (2020). <i>Journal of Number Theory</i>, <b>206</b>, 46-61.
					<br/><br/><br/>
					<a href="https://arxiv.org/abs/1904.12554" target="_blank">arXiv</a>
					&nbsp;&nbsp;/&nbsp;&nbsp;<a
                    <a href="https://doi.org/10.1016/j.jnt.2019.06.002" target="_blank">Journal</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=MR4013163" target="_blank">MathSciNet </a>
                </div>

                <b>2019</b>
                <div class="publist">
                    <a>
                        <img src="pubs/thumbs/farey.png" width="140" align="left"
                             style="margin-left:0px;margin-right:20px; border:1px solid #ddd"/>
                    </a>
                    <a href="pubs/partitions_to_hodge.pdf" target="_blank">
                        <b><i>From partitions to Hodge numbers of Hilbert schemes of surfaces</i></b><br/>
                    </a>
                    <u>Nate Gillman</u>, Xavier Gonzalez, Ken Ono, Larry Rolen, and Matthew Schoenbauer (2019).
                    <i>Philosophical Transactions of the Royal Society A</i>, <b>378</b>: 20180435.
                    <br/><br/>
                    <a href="https://arxiv.org/abs/1902.05421" target="_blank">arXiv</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://doi.org/10.1098/rsta.2018.0435" target="_blank">Journal</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=MR4055705" target="_blank">MathSciNet </a>
                </div>


                <b>2018</b>
                <div class="publist">
                    <a>
                        <img src="pubs/thumbs/circle_method.png" width="140" align="left"
                             style="margin-left:0px;margin-right:20px; border:1px solid #ddd"/>
                    </a>
                    <a href="pubs/hilbert_schemes.pdf" target="_blank">
                        <b><i>Exact formulas for invariants of Hilbert schemes</i></b><br/>
                    </a>
                    <u>Nate Gillman</u>, Xavier Gonzalez, and Matthew Schoenbauer (2018).
                    <i>Research in Number Theory</i> <b>4</b>(39).
                    <br/><br/>
                    <a href="https://arxiv.org/abs/1808.04431" target="_blank">arXiv</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://doi.org/10.1007/s40993-018-0132-z" target="_blank">Journal</a>
                    &nbsp;&nbsp;/&nbsp;&nbsp;
                    <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=MR3859828" target="_blank">MathSciNet </a>
                        
                </div>

      
            </div>

            <div class="section">
                <hr class="smooth">
                <h3>Updates </h3>
                <p>
                <ul>

                    <li>
                        [Oct-2024] Our arXiv <a href="https://arxiv.org/abs/2410.22269" target="_blank">preprint</a> proposes a new neural network layer, the Fourier head,
                        which learns a continuous probability density function using Fourier series, and returns a discrete approximation of it.
                        When to use it? Large language models are often adapted to model non-linguistic tokens. 
                        If these tokens have an underlying continuous structure, then replacing the linear classification head with the Fourier head can boost downstream performance.
                        You can find code and visuals on our <a href="https://nategillman.com/fourier-head" target="_blank">project page</a>.

                        <div id="tweet-container-fourier-head"></div>

                    </li>

                    <!-- <li>
                        [May-2024] Our paper <a href="https://nategillman.com/sc-sc.html" target="_blank">Self-Correcting Self-Consuming Loops for Generative Model Training</a> has been accepted at ICML 2024.
                        I'd love to connect with other researchers who will be in Vienna this summer!!
                    </li> -->

                    <li>
                        [Feb-2024] Our arXiv <a href="https://arxiv.org/abs/2402.07087" target="_blank">preprint</a> aims to stabilize self-consuming generative model training.
                        We support our proposed method with rigorous proofs, as well as experiments on the challenging human motion synthesis task.
                        You can find human motion visuals and code on our <a href="https://nategillman.com/sc-sc.html" target="_blank">project page</a>.

                        <div id="tweet-container-scsc"></div>

                    </li>

                    <!-- <li>
                        [June-2023] I've returned to grad school from my leave of absence in industry.
                    </li> -->

                    <!-- <li>
                        [June-2022] I'm taking a leave of absense from grad school to gain more exposure to AI in industry.
                    </li> -->

                    <!-- <li>
                        [Mar-2023] I joined 
                        <a href="https://www.captions.ai/" target="_blank">Captions</a>
                        as a machine learning engineer.
                    </li>

                    <li>
                        [Aug-2022] I joined 
                        <a href="https://www.akkio.com/" target="_blank">Akkio</a> 
                        as a machine learning engineer. I'm helping to build out the AutoML engine.
                    </li>

                    <li>
                        [Jun-2022] In summer 2022, I'm doing an machine learning internship at American Express in New York.
                        I'm in the Global Decision Science business unit, and my project involves working to improve chatbots for consumer services.
                    </li> -->

                    <!-- <li>
                        [May-2022] My collaborator <a href="http://brown.edu/Research/AI/people/william.html" target="_blank">William Rudman</a> presented our IsoScore paper at ACL 2022.
                    </li> -->

                    <!-- <li>
                        [Aug-2021] Our arXiv <a href="https://arxiv.org/abs/2108.07344" target="_blank">preprint</a> shows that previous metrics have been used incorrectly to analyze word embedding spaces.
                        We provide a mathematically sound method, which we call IsoScore.
                        We give rigorous proofs and we share an efficient Python <a href="https://github.com/bcbi-edu/p_eickhoff_isoscore" target="_blank">implementation</a>.

                        <div id="tweet-container-isoscore"></div>
                    </li> -->
                </ul>
                </p>
            </div>
        </div>

        <div id="footer"></div>
    </div>
</div>
</div>

<script>
            function toggleNews() {
              var moreNews = document.getElementById("moreNews");
              var moreNewsBtn = document.getElementById("moreNewsBtn");
              var lessNewsBtn = document.getElementById("lessNewsBtn");
              if (moreNewsBtn.style.display === "none") {
                moreNews.style.display = "none";
                moreNewsBtn.style.display = "inline";
                lessNewsBtn.style.display = "none";
              } else {
                moreNews.style.display = "inline";
                moreNewsBtn.style.display = "none";
                lessNewsBtn.style.display = "inline";
              }
            }
            function togglePubs() {
              var morePubs = document.getElementById("morePubs");
              var morePubsBtn = document.getElementById("morePubsBtn");
              var lessPubsBtn = document.getElementById("lessPubsBtn");
              if (morePubsBtn.style.display === "none") {
                morePubs.style.display = "none";
                morePubsBtn.style.display = "inline";
                lessPubsBtn.style.display = "none";
              } else {
                morePubs.style.display = "inline";
                morePubsBtn.style.display = "none";
                lessPubsBtn.style.display = "inline";
              }
            }
</script>

<!-- Default Statcounter code for Personal site
https://cs.brown.edu/people/ngillman/ -->
<script type="text/javascript">
    var sc_project=12967326; 
    var sc_invisible=1; 
    var sc_security="ad3f2dcd"; 
</script>
<script type="text/javascript"
    src="https://www.statcounter.com/counter/counter.js"
    async>
</script>
<noscript>
    <div class="statcounter">
        <a title="Web Analytics
            Made Easy - Statcounter" href="https://statcounter.com/"
            target="_blank">
            <img class="statcounter"
                src="https://c.statcounter.com/12967326/0/ad3f2dcd/1/"
                alt="Web Analytics Made Easy - Statcounter"
                referrerPolicy="no-referrer-when-downgrade">
        </a>
    </div>
</noscript>
    <!-- End of Statcounter Code -->

</body>
</html>
